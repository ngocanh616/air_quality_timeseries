
======================================================================
            BÃO CÃO Cáº¢I THIá»†N MÃ” HÃŒNH Dá»° BÃO PM2.5
======================================================================

ğŸ“Š Káº¾T QUáº¢ SO SÃNH:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MÃ´ hÃ¬nh        â”‚   RMSE   â”‚   MAE    â”‚    RÂ²    â”‚ Cáº£i thiá»‡n (%)  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ RF Baseline    â”‚   25.33  â”‚  12.32   â”‚  0.9492  â”‚      0.0%      â”‚
â”‚ XGBoost        â”‚   17.60  â”‚   8.69   â”‚  0.9767  â”‚    +30.5%      â”‚
â”‚ LightGBM       â”‚   16.16  â”‚   8.31   â”‚  0.9803  â”‚    +36.2%      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ† MÃ” HÃŒNH Tá»T NHáº¤T: LightGBM
   â”œâ”€ RMSE: 16.16 Î¼g/mÂ³
   â”œâ”€ MAE:  8.31 Î¼g/mÂ³
   â”œâ”€ RÂ²:   0.9803
   â””â”€ Cáº£i thiá»‡n: 36.2% so vá»›i baseline

ğŸ” PHÃ‚N TÃCH:

1ï¸âƒ£ Baseline Random Forest:
   â€¢ Model ban Ä‘áº§u vá»›i hyperparameters máº·c Ä‘á»‹nh
   â€¢ RMSE: 25.33, MAE: 12.32
   â€¢ Sá»­ dá»¥ng lag features vÃ  time features cÆ¡ báº£n

2ï¸âƒ£ XGBoost:
   â€¢ Gradient boosting máº¡nh máº½, cáº£i thiá»‡n 30.5%
   â€¢ RMSE: 17.60, MAE: 8.69
   â€¢ Xá»­ lÃ½ tá»‘t cÃ¡c má»‘i quan há»‡ phi tuyáº¿n
   â€¢ Thá»i gian training: trung bÃ¬nh

3ï¸âƒ£ LightGBM:
   â€¢ Hiá»‡u quáº£ nháº¥t, cáº£i thiá»‡n 36.2% so vá»›i baseline
   â€¢ RMSE: 16.16, MAE: 8.31
   â€¢ Tá»‘c Ä‘á»™ training nhanh nháº¥t
   â€¢ PhÃ¹ há»£p cho production vá»›i dá»¯ liá»‡u lá»›n

ğŸ’¡ SO SÃNH CHI TIáº¾T:

ğŸ“ˆ Äá»™ chÃ­nh xÃ¡c (RMSE):
   â€¢ LightGBM < XGBoost < RF Baseline
   â€¢ LightGBM giáº£m 9.17 Î¼g/mÂ³ so vá»›i baseline

ğŸ“‰ Sai sá»‘ tuyá»‡t Ä‘á»‘i (MAE):
   â€¢ LightGBM < XGBoost < RF Baseline
   â€¢ Cáº£ 2 models gradient boosting Ä‘á»u vÆ°á»£t trá»™i

âš¡ Tá»‘c Ä‘á»™ training:
   â€¢ LightGBM > XGBoost > RF
   â€¢ LightGBM nhanh hÆ¡n ~2-3x so vá»›i XGBoost

ğŸ’¡ KHUYáº¾N NGHá»Š:

âœ… Sá»­ dá»¥ng LightGBM cho production:
   â€¢ Äá»™ chÃ­nh xÃ¡c cao nháº¥t
   â€¢ Tá»‘c Ä‘á»™ inference nhanh
   â€¢ Dá»… deploy vÃ  maintain

ğŸ”§ Cáº£i thiá»‡n tiáº¿p theo:
   â€¢ Hyperparameter tuning chi tiáº¿t hÆ¡n vá»›i GridSearchCV
   â€¢ ThÃªm features: interaction terms, polynomial features
   â€¢ Ensemble nhiá»u models (stacking/blending)
   â€¢ Feature selection Ä‘á»ƒ giáº£m overfitting

ğŸ“Š Monitoring:
   â€¢ Track RMSE/MAE trÃªn production data
   â€¢ Retrain model Ä‘á»‹nh ká»³ (hÃ ng thÃ¡ng/quÃ½)
   â€¢ A/B testing giá»¯a cÃ¡c model versions

======================================================================
